{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 31009 - Final Project - RNNs Model\n",
    "### Ada, Rohit, Dylan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd \n",
    "import re   \n",
    "import nltk  \n",
    "from nltk.corpus import stopwords           \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from collections import Counter  \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt     \n",
    "from IPython.core.display import display, HTML  \n",
    "import string\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer  \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences   \n",
    "from tqdm import tqdm  \n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.layers import Embedding,SimpleRNN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import optimizers,initializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Load Data\n",
    "train = pd.read_csv(\"Cleaned_Train.csv\")\n",
    "train_y = train.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this earthquake Ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to shelter in place are be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13000 people receive wildfire evacuation order...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby Alaska as s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this earthquake Ma...   \n",
       "1   4     NaN      NaN              Forest fire near La Ronge Sask Canada   \n",
       "2   5     NaN      NaN  All residents asked to shelter in place are be...   \n",
       "3   6     NaN      NaN  13000 people receive wildfire evacuation order...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby Alaska as s...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer sequence and index words\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train.text)   \n",
    "word_index = tokenizer.word_index    \n",
    "num_words = len(tokenizer.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words: 17440\n"
     ]
    }
   ],
   "source": [
    "print('Number of unique words:',len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sequences = tokenizer.texts_to_sequences(train.text)  \n",
    "\n",
    "# Ading padding at the front of text sequence\n",
    "training_padded = pad_sequences(training_sequences,                                  \n",
    "                                   maxlen=50,                                      \n",
    "                                   padding='pre',                           \n",
    "                                   truncating='pre')  \n",
    "\n",
    "# Split data set for further training and validation\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(training_padded, train_y, test_size=.25,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17440/17440 [00:00<00:00, 530408.69it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(17441, 300)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matching words with Glove embedding 6B.300D\n",
    "embedding_dict={}\n",
    "with open('glove.6B.300d.txt','r',encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values=line.split()\n",
    "        word=values[0]\n",
    "        vectors=np.asarray(values[1:],'float32')\n",
    "        embedding_dict[word]=vectors\n",
    "f.close()\n",
    "\n",
    "embedding_dim=300\n",
    "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
    "\n",
    "for word, i in tqdm(word_index.items()):\n",
    "    if i < num_words:\n",
    "        embedding_vector = embedding_dict.get(word)  \n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN without LSTM Layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 50, 300)           5232300   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 50, 300)           0         \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, 64)                23360     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 5,255,725\n",
      "Trainable params: 23,425\n",
      "Non-trainable params: 5,232,300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Building the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=num_words,\n",
    "                    output_dim=300,\n",
    "                    embeddings_initializer=initializers.Constant(embedding_matrix), \n",
    "                    input_length=50,trainable=False))\n",
    "model.add(Dropout(0.2)) \n",
    "model.add(SimpleRNN(units=64, activation=\"sigmoid\"))\n",
    "model.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6383 - accuracy: 0.6295 - val_loss: 0.6050 - val_accuracy: 0.6835\n",
      "Epoch 2/10\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.5205 - accuracy: 0.7508 - val_loss: 0.4886 - val_accuracy: 0.7780\n",
      "Epoch 3/10\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.4861 - accuracy: 0.7825 - val_loss: 0.4770 - val_accuracy: 0.7892\n",
      "Epoch 4/10\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.4572 - accuracy: 0.7972 - val_loss: 0.4919 - val_accuracy: 0.7752\n",
      "Epoch 5/10\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.4447 - accuracy: 0.8040 - val_loss: 0.4738 - val_accuracy: 0.7920\n",
      "Epoch 6/10\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.4379 - accuracy: 0.8068 - val_loss: 0.4873 - val_accuracy: 0.7829\n",
      "Epoch 7/10\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.4253 - accuracy: 0.8164 - val_loss: 0.5107 - val_accuracy: 0.7773\n",
      "Epoch 8/10\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.4309 - accuracy: 0.8143 - val_loss: 0.4696 - val_accuracy: 0.7962\n",
      "Epoch 9/10\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.4224 - accuracy: 0.8201 - val_loss: 0.4736 - val_accuracy: 0.7885\n",
      "Epoch 10/10\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.4262 - accuracy: 0.8129 - val_loss: 0.4773 - val_accuracy: 0.7829\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 0.4686 - accuracy: 0.7952\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4686012864112854, 0.7951680421829224]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the mode and evaluate the model\n",
    "model_1_fit = model.fit(X_train, Y_train, validation_split=.25, epochs=10, batch_size=10)\n",
    "model.evaluate(X_test, Y_test, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "#Save model file to disk\n",
    "model_json = model.to_json()\n",
    "with open(\"rnnmodel.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"rnnmodel.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN with LSTM Layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 50, 300)           5232300   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50, 300)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 5,325,805\n",
      "Trainable params: 93,505\n",
      "Non-trainable params: 5,232,300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Building the model\n",
    "model2 = Sequential()\n",
    "model2.add(Embedding(input_dim=num_words,\n",
    "                    output_dim=300,\n",
    "                    embeddings_initializer=initializers.Constant(embedding_matrix), \n",
    "                    input_length=50,trainable=False))\n",
    "\n",
    "model2.add(Dropout(0.2)) \n",
    "model2.add(LSTM(64,dropout=0.2, recurrent_dropout=0.2))\n",
    "model2.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "model2.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 0.4966 - accuracy: 0.7669 - val_loss: 0.4458 - val_accuracy: 0.7997\n",
      "Epoch 2/10\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 0.4220 - accuracy: 0.8127 - val_loss: 0.4402 - val_accuracy: 0.8109\n",
      "Epoch 3/10\n",
      "429/429 [==============================] - 9s 22ms/step - loss: 0.3975 - accuracy: 0.8227 - val_loss: 0.4478 - val_accuracy: 0.8088\n",
      "Epoch 4/10\n",
      "429/429 [==============================] - 10s 24ms/step - loss: 0.3648 - accuracy: 0.8454 - val_loss: 0.4595 - val_accuracy: 0.8032\n",
      "Epoch 5/10\n",
      "429/429 [==============================] - 10s 24ms/step - loss: 0.3453 - accuracy: 0.8500 - val_loss: 0.4668 - val_accuracy: 0.8011\n",
      "Epoch 6/10\n",
      "429/429 [==============================] - 10s 24ms/step - loss: 0.3197 - accuracy: 0.8655 - val_loss: 0.4734 - val_accuracy: 0.7990\n",
      "Epoch 7/10\n",
      "429/429 [==============================] - 10s 24ms/step - loss: 0.2946 - accuracy: 0.8753 - val_loss: 0.4894 - val_accuracy: 0.8032\n",
      "Epoch 8/10\n",
      "429/429 [==============================] - 11s 25ms/step - loss: 0.2624 - accuracy: 0.8865 - val_loss: 0.4897 - val_accuracy: 0.7822\n",
      "Epoch 9/10\n",
      "429/429 [==============================] - 11s 26ms/step - loss: 0.2307 - accuracy: 0.9073 - val_loss: 0.5210 - val_accuracy: 0.7941\n",
      "Epoch 10/10\n",
      "429/429 [==============================] - 11s 25ms/step - loss: 0.2121 - accuracy: 0.9147 - val_loss: 0.5663 - val_accuracy: 0.7864\n",
      "191/191 [==============================] - 1s 3ms/step - loss: 0.5598 - accuracy: 0.7910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5597984194755554, 0.7909663915634155]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the mode and evaluate the model\n",
    "model_2_fit = model2.fit(X_train, Y_train, validation_split=.25, epochs=10, batch_size=10)\n",
    "model2.evaluate(X_test, Y_test,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "#Save model file to disk\n",
    "model2_json = model2.to_json()\n",
    "with open(\"rnn2model.json\", \"w\") as json_file:\n",
    "    json_file.write(model2_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"rnn2model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
